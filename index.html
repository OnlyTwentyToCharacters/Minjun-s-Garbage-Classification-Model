<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Garbage Classifier</title>
  <style>
    body {
      font-family: sans-serif;
      text-align: center;
      padding: 2em;
      background-color: #f9f9f9;
    }

    #preview {
      max-width: 100%;
      height: auto;
      margin-top: 1em;
    }

    #result {
      margin-top: 1em;
      font-size: 1.5em;
      font-weight: bold;
      background: #f0f0f0;
      padding: 1em;
      border-radius: 10px;
      display: inline-block;
    }

    button, input[type="file"] {
      margin: 0.5em;
      padding: 0.75em 1.5em;
      font-size: 1em;
      border: none;
      border-radius: 30px;
      background-color: #4CAF50;
      color: white;
      cursor: pointer;
      transition: background-color 0.3s ease;
    }

    button:hover, input[type="file"]:hover {
      background-color: #45a049;
    }

    input[type="file"] {
      background-color: #2196F3;
    }

    input[type="file"]::file-selector-button {
      font-weight: bold;
      padding: 0.5em 1em;
      border: none;
      border-radius: 20px;
      background-color: #1976D2;
      color: white;
      cursor: pointer;
    }

    input[type="file"]::file-selector-button:hover {
      background-color: #1565C0;
    }
  </style>
</head>
<body>
  <h1>Garbage Type Detector</h1>
  <input type="file" id="file-input" accept="image/*" />
  <img id="preview" src="" alt="Preview"/>
  <div id="result"></div>

  <!-- ONNX Runtime Web -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  
  <script>
    let session;
    const modelPath = "resnet34.onnx";
    const labels = ["battery", "cardboard", "glass", "metal", "paper", "plastic", "trash"];
    const inputName = "input_0";

    async function initModel() {
      session = await ort.InferenceSession.create(modelPath, { executionProviders: ['wasm'] });
      console.log("Model loaded:", session);
    }

    function preprocess(img) {
      const canvas = document.createElement("canvas");
      canvas.width = 224;
      canvas.height = 224;
      const ctx = canvas.getContext("2d");
      ctx.drawImage(img, 0, 0, 224, 224);
      const imgData = ctx.getImageData(0, 0, 224, 224).data;
      const tensorData = new Float32Array(1 * 3 * 224 * 224);
      let offset = 0;
      for (let i = 0; i < imgData.length; i += 4) {
      tensorData[offset++] = imgData[i] / 255;
      tensorData[offset++] = imgData[i + 1] / 255;
      tensorData[offset++] = imgData[i + 2] / 255;

      }
      const inputTensor = new ort.Tensor("float32", tensorData, [1, 3, 224, 224]);
      return inputTensor;
    }

    function softmax(arr) {
      const max = Math.max(...arr);
      const exps = arr.map(x => Math.exp(x - max));
      const sum = exps.reduce((a, b) => a + b);
      return exps.map(e => e / sum);
    }

    async function runInference(img) {
      document.getElementById("preview").src = img.src;
      const inputTensor = preprocess(img);
      const feeds = { [inputName]: inputTensor };
      const results = await session.run(feeds);
      const output = results[Object.keys(results)[0]].data;

      const probs = softmax(output);
      const maxProb = Math.max(...probs);
      const idx = probs.indexOf(maxProb);
      const percent = (maxProb * 100).toFixed(2);

      document.getElementById("result").innerHTML = `
        <div>Detected: <strong>${labels[idx]}</strong></div>
        <div>Confidence: <strong>${percent}%</strong></div>
      `;
    }

    document.getElementById("file-input").addEventListener("change", event => {
      const file = event.target.files[0];
      if (!file) return;
      const img = new Image();
      img.onload = () => runInference(img);
      img.src = URL.createObjectURL(file);
    });

    initModel();
  </script>
</body>
</html>

